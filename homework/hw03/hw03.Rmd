---
author: "Matej Popovski"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message=FALSE, warning = FALSE,
                      fig.height = 3,
                      error = TRUE)
library(tidyverse)
source("../../scripts/viridis.R")
```

## Assignment 3

### Preliminaries

Code to read in data and source the *viridis.R* file assumes: (1) that you have the following directories and files, where COURSE is the path to your top course directory (it might be something like "~/Documents/stat240"); (2) that you have set the *hw03* directory to be your working directory; and (3) that you have installed both the **tidyverse** and **viridisLite** packages.

- Directories
    - COURSE/homework/
    - COURSE/homework/hw03/
    - COURSE/data/
    - COURSE/scripts/
- Files
    - COURSE/homework/hw03/hw03.Rmd
    - COURSE/data/madison-weather-official-1969-2023.csv
    - COURSE/data/exoplanets-clean-through-2022.csv
    - COURSE/scripts/viridis.R

#### Notes

- You will need to install the `viridisLite` package if you have not done so already.
- Code in the file `viridis.R` changes the default color scheme in `ggplot2` so that:
    - default colors are easier to perceive by people with a variety of color blindness conditions
    - when color is used to represent a continuous variable, perception of changes of shade are more even than in the default choice.
- Replace the text "YOUR NAME HERE" in the YAML section with your name.
- Edit this file, answer the questions, knit, and submit your solutions by uploading the resulting HTML file to the course Canvas site.  Be sure to review your HTML and ensure that your solutions appear as you expect prior to submitting.
- Post questions using Discord, visit the Learning Center, or attend office hours if you have questions.

### Aims

- Refine and expand **ggplot2** skills for making plots, including:
    - changing axis scales
    - using color and size
    - making bar plots for categorical data
    - breaking plots over multiple facets
- Demonstrate skills from **dplyr** for wrangling and summarizing data


### Problems

The following R chunk reads in the default exoplanet data,
selects some variables, and changes some variable names.
*Note: This data set is not the same as what you used in discussion this week. It has already been reduced to a file with one unique exoplanet per row and variables have been selected and renamed.*

```{r read-planet-data}
## Read in the csv file
planets = read_csv("../../data/exoplanets-clean-through-2022.csv") 
planets
```

  1. A small number of planets have both an estimated mass AND an estimated radius less than those of the Earth.  What are the names of these planets, what method(s) were used to detect them, and in what year were they discovered?

- Create a data summary table with the star name, planet name, method, year, mass, and radius of the planets that have **both** an estimated mass < 1 Earth mass **and** an estimated radius < 1 Earth radius.  
- Order the rows increasing by mass.
- Print the entire table.

```{r}
## Add your code here

name1 = planets %>%
          select(-id) %>%
          #drop_na(radius) %>%
          #drop_na(mass) %>%
          filter(mass<1 & radius<1) %>% 
          arrange(mass)
name1  

```




  2. Using the exoplanet data table `planets`:

- filter so that you only use planets discovered by the radial velocity method;
- remove cases where either of the variables `year` or `mass` (or both) are missing;
- for this subset of exoplanets, create a table with a data summary with the number of planets discovered and the minimum mass of these planets by year
- print the first 10 rows and all columns of this data summary

Then, make a scatter plot of this data such that:

- the size of points are proportional to the number of planets discovered that year
- the y-axis is on the log10 scale *(hint:  consider `scale_y_continuous()` or `scale_y_log10()`)*
- the axes have descriptive labels, and
- the plot contains an informative title.

Note, a scatter plot where the size of the points is proportional to a numerical variable is called a *bubble plot*.

In addition to creating the graphic, respond to the question below the R chunk.

```{r}
### Add your code here
name2 = planets %>%
          #select(-id) %>%
          drop_na(year) %>%
          drop_na(mass) %>%
          group_by(year) %>%
          filter(method == "Radial Velocity") %>%
          summarise(numOfPlanetsDiscovered = n(), minMass= min(mass)) #%>%
          #slice_min(mass, n=10)
#name2  
head(name2, 10) ##should it be sorted by anything??

ggplot(head(name2, 10), aes(x = year, y = numOfPlanetsDiscovered)) +        ##can I use head(name2, 10) as input var?
  geom_point(size = numOfPlanetsDiscovered) +                               ## bubble plot?
  geom_line() +
  geom_smooth(se = FALSE) +
  labs(
    x = "Year",
    y = "Number of Planets Discovered",
    title = "Madison Average Annual Temperature Over Time",
 ) + scale_y_log10()
```


**Describe the pattern between year and minimum mass of planet discovered using Radial Velocity.**

> [Type your answer here]




  3. Using the `planets` data set created at the beginning of the assignment
*(not the reduced data set from the previous problem)*,
determine which methods have been used to discover fewer than 30 planets each. For use in the remaining exoplanet problems,
create a subset of the data by:

- removing the planets discovered by those methods (with fewer than 30 exoplanet  discoveries)
    - *(Hint: Consider creating a column which contains for each case the total number of times that the corresponding method appears in the data set and then using this information inside of `filter()`.)*
    
> Print a summary table with the methods used at least 30 times and the total number of exoplanets discovered by each, arranged from highest to lowest.

- summarize *for each year*, the number of planets and the proportion of planets discovered by each method used 30 or more times. *(Note: filter to keep only methods that are used 30 or more times in the entire data set. Counts in a single year may be less.)*
  - proportions should sum to one within each year.
- arrange the rows by year in chronological order (earliest first)

This data summary should have one row for each year and method (if the method was used in that year) and columns with the names `year`, `method`, `n`, and `proportion`.
*(Hint: you may find it helpful also to create a `total` column with the total number of exoplanets discovered each year repeated for each row to help calculate the proportion.)*

```{r}
### Add your code here
```

Print the first 10 rows and all columns of this data summary.

```{r}
### Add your code here
```





  4. Using the data summary from the previous problem, create and display a bar plot with the year on the x axis and the proportion of discovered planets on the y axis.  Let each year have a single bar that extends from a proportion of 0 to 1, with sections of each bar filled with a color by method
Add appropriate axis labels and plot title.

```{r}
### Add your code here
```


Which method was most successful with the earliest discoveries of exoplanets, and which method has supplanted that method in relative popularity in recent years?

> [Type your answer here]







  5. Begin with the data summary from the previous problem.

- filter to only include years from 2010 -- 2022 (include the endpoints of the range), and
- remove the rows corresponding to the "Transit" or "Radial Velocity" methods.

Using this modified data set, create a plot which:

- displays the *counts* of exoplanets discovered by method with a bar graph with year on the x axis, different fill colors for each method,
and the *counts* of the number of planets for each year and method on the y axis using the function `geom_col()`.
- does not stack the bars for each year, but rather display them next to each other in a clump by each year label.
(*Note: The default is to stack bars. Use the argument `position = position_dodge2(preserve = "single")` inside of `geom_col()` to avoid stacking and to preserve the same bar width when the number of methods present changes by year.*)
- adjusts the x-axis so a tick mark and label appears for each year (i.e., 2010, 2011, ..., 2022).  **(Hint: consider `scale_x_continuous()`.)**
- uses appropriate axis labels and plot title.

```{r}
## Add your code here
```





```{r, include = FALSE}
official = read_csv("../../data/madison-weather-official-1869-2023.csv")
```

  6. Use the official Madison weather data. Find:

- **6a**. The dates with the five highest recorded maximum temperatures (there could be more than five dates due to ties)

```{r}
## Add your code here
```



- **6b**. The proportion of all days by month with positive precipitation.

```{r}
## Add your code here
```



- **6c**. The average temperature (mean of `tavg`) by month for the years from 1991-2020. Consider these values to be the current *normal mean temperatures*. Then, find the average temperature by month in 2022. In how many months was the average temperature in 2022 higher than the normal mean temperature?

```{r}
## Add your code here
```

> [Type your answer here]




- **6d**. The ten years with the highest average temperature on record since 1869. How many of these years have occurred since 2000?

```{r}
## Add your code here
```




  7. The combined total monthly precipitation in Madison in 2023 was 0.95 inches in May and 1.14 inches in June.

- Calculate the total monthly precipitation for each May and for each June by year from the official daily Madison weather data from 1869--2023.
The resulting data set should have two rows for each of the years and columns for year, month, and total precipitation.
- Create a single summary data table with the 25 lowest precipitation months for May, from the years 1869--2023, ranked from smallest to largest. Add a leading column named `rank` with the values from 1 to 25 (don't worry about making the numbers right if there are ties).
    - This summary table should have columns `rank`, `year`, `month`, and the total precipiation in inches.

> Where did May 2023 rank among the driest Mays in recorded Madison history?

> Repeat for June. Where did May 2023 rank among the driest Mays in recorded Madison history?
  
  
```{r}

```

> Write your answers here
  
  8. Return to the monthly total precipitation table for the months of May and June from 1869--2023. Create a new summary table by calculating the combined total for May and June within each year by summing the May and June totals.

- This summary table should have a column for `year` and a column for the combined total precipitation in May and June.

- Make a plot which shows the combined total precipitation in May and June in Madison from 1869--2023 versus the year. Add a smooth trend curve to the plot. Add a red dashed horizontal line at the combined total precipitation in May and June for 2023. Include meaningful axis labels and a title for the plot.
- Comment on how the combined precipitation in these two months in 2023 compares to the historical weather record.
  
```{r}

```



