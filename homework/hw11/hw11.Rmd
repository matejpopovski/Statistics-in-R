---
author: "Matej Popovski"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, fig.height = 4)
library(tidyverse)
library(scales)
library(modelr)
source("../../scripts/viridis.R")
source("../../scripts/ggprob.R")
```

\renewcommand{\prob}{\mathsf{P}}
\newcommand{\E}{\mathsf{E}}
\newcommand{\Var}{\mathsf{Var}}
\newcommand{\SD}{\mathsf{SD}}
\newcommand{\SE}{\mathsf{SE}}

## Homework Assignment 11

### Preliminaries

- Directories
    - COURSE/homework/
    - COURSE/homework/hw11/
    - COURSE/data/
    - COURSE/scripts/
- Files
  - COURSE/homework/hw11/hw11.Rmd
  - COURSE/data/boston-marathon-data.csv
  - COURSE/data/dugong.csv
  - COURSE/scripts/viridis.R
  - COURSE/scripts/ggprob.R

### Data

- Some problems use a new data set on lengths and ages of a sample of dugongs in the file `dugong.csv`.
- Additional problems use the Boston Marathon data in the file `boston-marathon-data.csv`. This file is a transformed version of the raw data we used in class and has data for all runners who completed the race in 2010 and 2011. The variable `Time` is the sum of the times from the different portions of the race, each of which begins with "K".

### Aims

- Practice regression

## Problems

### 1.
In a regression problem to estimate $y$ from explanatory variable $x$ from a sample of size $n$, partial summary information is $\bar{x} = 20$ and $\bar{y} = 100$. Regardless of the values of other summary statistics, what is the value the predicted value $\hat{y}$ at a point where $x = 20$? Briefly explain.
  
> x and y bar are the averrage of the xs and ys and they lay on the regression line. Hence, we are looking for y hat which is necessarily on the line, and  I can conclude that the value of yhat is 100.




###  2.
In a regression problem to estimate $y$ from explanatory variable $x$ from a sample of size $n$, partial summary information is $\bar{x} = 20$, $s_x = 5$, $\bar{y} = 100$, and $s_y = 15$. Which of the following values are possible values for the predicted value $\hat{y}$ when the explanatory variable has value $x = 30$? Briefly explain.
  
**(a)** 50      
**(b)** 70      
**(c)** 100      
**(d)** 120    
**(e)** 150

> The answer is b, c and d. Since we dont know whether the line has positive or negative slope, we need to consider both cases. x = 30 is two standard deviations from xmean=20, hence we assume that yhat varies also 2 standard deviations which would be +- 2*15. So the range of correct options would be between 70 and 130.

Problems 3--6 are based on the data set in the file *dugong.csv* which relates age (in years) and length (in meters) of a sample of 27 dugongs, a type of marine mammal.
  
Credit:  The *dugong.csv* file is from Data8 at UC-Berkeley.


### 3.
Read the dugong data.
Create a scatter plot with `length` on the x-axis and `age` on the y-axis.

- Add descriptive axis labels (include units of measurement) and a title.  
- Using `geom_smooth()`, add the least-squares line to your plot.

```{r}
data = read_csv("../../data/dugong.csv")
#data

ggplot(data, aes(x = Length, y = Age)) +
  geom_point() +
  xlab("Dugongs Length (Meters)") +
  ylab("Age (Years)") +
  ggtitle("Relationship between Dugongs Age (Years) and Length (Meters)") +
  geom_smooth(se = FALSE, method = "lm") + 
  theme_bw() +
  theme(text = element_text(size = 20)) 

```





### 4.

-4a. Using the dugong data, calculate the sample means, sample standard deviations, and correlation coefficient of the variables `age` and `length`.

```{r}
data2 = data %>%
  summarise(meanAge = mean(Age), meanLength = mean(Length), sdAge = sd(Age), sdLength = sd(Length), corelationCoefficient = cor(Length, Age))
data2

```

-4b. Using formulas from lecture, calculate the slope and intercept of the least squares regressions line to predict age with length.

```{r}

beta_hat_1 = data2$corelationCoefficient * data2$sdAge / data2$sdLength
beta_hat_0 = data2$meanAge - beta_hat_1 * data2$meanLength

c(beta_hat_1, beta_hat_0)

```

-4c. Use the dugong data and the functions `lm()` and `coef()` to calculate the slope and intercept of the least squares regression line of age against length (use length to predict age).

```{r}
model_object = lm(data$Age ~ data$Length)
model_object

estimates = coef(model_object)
estimates

```

-4d. Verify that you get the same values for the slope and mean in 4b and 4c.


> Yes I get the same values. The line equation is: y = 23.77168 * x - 44.56683



### 5.

-5a. Add columns with the predicted values and residuals to the dugong data set. *(You can use* **modelr** *functions or just use `mutate()` and calculate these values directly.)* Print the first 10 rows of this modified data set

```{r}
resid(model_object)

data %>% 
  mutate(resid = resid(model_object)) %>% 
  head(10)


```

-5b. Plot the residuals versus length.

- Add a horizontal line at $y=0$ and appropriate labels on each axis.

```{r}
dugong_with_residuals = data %>% 
  add_residuals(model_object)
# dugong_with_residuals

ggplot(dugong_with_residuals, aes(x = Length, y = resid)) +
  geom_point() +
  geom_hline(yintercept = 0) + 
  geom_smooth(se = F)


```



-5c. Describe what the residual plot suggests about the appropriateness of using simple linear regression to predict age from length of dugongs.

> Since there is visual non linear (quadratic function) line, I can note that linear function is not appropriate to approximate the trend of the lines. One more note is that sigma is not constant for different lengths.
> The residual plot provides insight into whether the residuals are randomly dispersed around the horizontal line at y = 0 or if they display any systematic pattern. Since there is visual non linear function.




### 6.

-6a. Print the summary of the fitted regression model using `lm()` from problem 4.

```{r}

summary(model_object)

```

- The simple linear regression model for $Y_i$ conditional on the values of $X_i = x_i$ is

$$
Y_i = \beta_0 + \beta_1 x_i + \varepsilon_i, \quad \text{for $i = 1, \ldots,n$}
$$

where $\varepsilon_i \sim \text{Normal}(0, \sigma)$
for some parameter $\sigma > 0$.

- The parameter $\sigma$ is the unknown population standard deviation of the typical distance between a point $Y_i$ and its expected value, $\E(Y_i \mid X_i = x_i) = \beta_0 + \beta_1 x_i$.

-6b. Use the function `sigma()` on the fitted regression object (what you created with `lm()`) to extract the numerical value of the estimate of $\sigma$. Check that this value matches the printed value of the model summary in 6a. Print this value.

```{r}

sigma(model_object)

```

- The numerical estimate of $\sigma$ here is not quite the standard deviation of the residuals because the denominator is $n-2$, the degrees of freedom in simple linear regression, instead of $n-1$, the degrees of freedom from a single numerical sample.

-6c. Use the column of residuals in the augments data set `dugong` and verify that:

- the mean of the residuals equals zero (numerically, it might be very close, but not exactly equal, to zero).
- you arrive at the numerical estimate of $\sigma$ by calculating
    
$$
\sqrt{ \frac{\sum_{i=1}^n (y_i - \hat{y}_i)^2}{n-2} }
$$

where the $i$th residual is $y_i - \hat{y}_i$.

```{r}
res = dugong_with_residuals$resid
n = nrow(dugong_with_residuals)

sqrt(sum(res^2)/(n-2))


```







- Problems 7--8 use the cleaned Boston Marathon data in `boston-marathon-data.csv`.


### 7.

- Read in the Boston marathon data from the file `boston-marathon-data.csv`.

```{r}
boston_data = read_csv("../../data/boston-marathon-data.csv")
boston_data
```

-7a. Create a scatter plots of `Time` versus `Age` for the female runners in 2010.

- Add a straight regression line
- Add a smooth curve
- As there are so many points, you may set `alpha` to a value less than one inside of `geom_point()` to lessen the effects of over-plotting.    
    
```{r}
boston_data2 = boston_data %>%
  filter(Sex == "female" & Year == 2010)


ggplot(boston_data2, aes(x = Age, y = Time)) +
  geom_point(alpha = 1/10) +
  xlab("Age of runner") +
  ylab("Time accomplished") +
  ggtitle("Relationship between Runners Age (Years) and Time accomplishjed (Minutes) ") +
  geom_smooth(se = FALSE, method = "lm") + # Recall: se = FALSE takes away the "ribbon", method = "lm" makes the line straight. More on these arguments later in this lecture!
  theme_bw() +
  theme(text = element_text(size = 20)) +
  geom_smooth(se = F, color = "red")


```
    
-7b. Make a residual plot of the residuals versus `Age`.

- Include a horizontal line at $y=0$
- Include a smooth curve through the residuals

```{r}
model_object2 = lm(Time ~ Age, boston_data2)
#model_object2

boston_data2 = boston_data2 %>% 
  add_residuals(model_object2) 


ggplot(boston_data2, aes(x = Age, y = resid)) +
  geom_point(alpha = 1/10) +
  geom_hline(yintercept = 0) + 
  geom_smooth(se = F)


```

-7c. Make a density plot of the residuals.


```{r}

ggplot(boston_data2, aes(x = resid)) +
  geom_density() +
  xlab("Residual of runners timing") 

```






### 8.
Examine the residual plots from the previous problem.
  
-8a. Is there evidence of strong non-linearity?

> Since there is a visual curved line, yes, there is evidence of strong non-linearity.

-8b. Is there evidence that the standard deviation of the residuals varies substantially with changes in age?

> There is no evidence showing that the standard deviastion of the residuals varies substantially with the change in age.


-8c. Is there evidence that the error distribution for individual residuals is not symmetric?

> Yes there is evidence showing that the error distributon for indicidual residuals is not symmetric. The density graph is right skewed. 


